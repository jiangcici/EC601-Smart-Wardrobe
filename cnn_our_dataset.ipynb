{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/Users/antonygomez/Desktop/AnacondaInstall/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "247\n",
      "(246,)\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
    "from keras.optimizers import SGD,RMSprop,adam\n",
    "from keras.utils import np_utils\n",
    "import keras\n",
    "from __future__ import print_function\n",
    "from keras import backend as K\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import os\n",
    "import theano\n",
    "from PIL import Image\n",
    "from numpy import *\n",
    "# SKLEARN\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 200, 200\n",
    "\n",
    "# number of channels\n",
    "img_channels = 1\n",
    "\n",
    "#  data\n",
    "\n",
    "path1 = '/Users/antonygomez/Desktop/ML_learn/image_dataset'\n",
    "#path of folder of images    \n",
    "path2 = '/Users/antonygomez/Desktop/ML_learn/image_resized'\n",
    "#path of folder to save images    \n",
    "\n",
    "listing = os.listdir(path1)\n",
    "num_samples=size(listing)\n",
    "print(num_samples)\n",
    "\n",
    "for file in listing:\n",
    "    if file=='.DS_Store':\n",
    "        continue\n",
    "    else:\n",
    "        im = Image.open(path1 + '//' + file)\n",
    "        img = im.resize((img_rows,img_cols))\n",
    "        gray = img.convert('L')\n",
    "\t#need to do some more processing here           \n",
    "        gray.save(path2 +'//' + file, \"JPEG\")\n",
    "\n",
    "imlist = os.listdir(path2)\n",
    "\n",
    "im1 = array(Image.open('/Users/antonygomez/Desktop/ML_learn/image_resized' + '//'+ imlist[0]))\n",
    "# open one image to get size\n",
    "m,n = im1.shape[0:2]\n",
    "# get the size of the images\n",
    "imnbr = len(imlist)\n",
    "# get the number of images\n",
    "\n",
    "# create matrix to store all flattened images\n",
    "immatrix = array([array(Image.open('/Users/antonygomez/Desktop/ML_learn/image_resized'+ '//' + im2)).flatten()for im2 in imlist],'f')\n",
    "label=np.ones((num_samples-1,),dtype = int)\n",
    "label[0:56]=0\n",
    "label[56:95]=1\n",
    "label[95:146]=2\n",
    "label[146:197]=3\n",
    "label[197:]=4\n",
    "print(label.shape)\n",
    "data,Label = shuffle(immatrix,label, random_state=2)\n",
    "train_data = [data,Label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (196, 200, 200, 1)\n",
      "196 train samples\n",
      "50 test samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/antonygomez/Desktop/AnacondaInstall/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:52: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), input_shape=(200, 200,..., padding=\"valid\")`\n",
      "/Users/antonygomez/Desktop/AnacondaInstall/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:55: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3))`\n",
      "/Users/antonygomez/Desktop/AnacondaInstall/anaconda3/lib/python3.6/site-packages/keras/models.py:848: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 156 samples, validate on 40 samples\n",
      "Epoch 1/30\n",
      "156/156 [==============================] - 29s - loss: 4.7228 - acc: 0.1731 - val_loss: 1.6008 - val_acc: 0.2500\n",
      "Epoch 2/30\n",
      "156/156 [==============================] - 26s - loss: 1.6299 - acc: 0.2564 - val_loss: 1.5666 - val_acc: 0.2750\n",
      "Epoch 3/30\n",
      "156/156 [==============================] - 26s - loss: 1.5915 - acc: 0.2372 - val_loss: 1.5780 - val_acc: 0.2750\n",
      "Epoch 4/30\n",
      "156/156 [==============================] - 28s - loss: 1.5886 - acc: 0.2564 - val_loss: 1.5492 - val_acc: 0.2750\n",
      "Epoch 5/30\n",
      "156/156 [==============================] - 28s - loss: 1.4978 - acc: 0.2821 - val_loss: 1.5341 - val_acc: 0.3250\n",
      "Epoch 6/30\n",
      "156/156 [==============================] - 28s - loss: 1.5995 - acc: 0.2692 - val_loss: 1.5965 - val_acc: 0.2500\n",
      "Epoch 7/30\n",
      "156/156 [==============================] - 27s - loss: 1.5747 - acc: 0.2692 - val_loss: 1.5773 - val_acc: 0.1750\n",
      "Epoch 8/30\n",
      "156/156 [==============================] - 25s - loss: 1.4704 - acc: 0.3333 - val_loss: 1.5221 - val_acc: 0.2750\n",
      "Epoch 9/30\n",
      "156/156 [==============================] - 25s - loss: 1.4100 - acc: 0.3910 - val_loss: 1.4924 - val_acc: 0.2500\n",
      "Epoch 10/30\n",
      "156/156 [==============================] - 21s - loss: 1.3457 - acc: 0.4359 - val_loss: 1.3205 - val_acc: 0.4500\n",
      "Epoch 11/30\n",
      "156/156 [==============================] - 24s - loss: 1.2315 - acc: 0.5128 - val_loss: 1.2655 - val_acc: 0.4250\n",
      "Epoch 12/30\n",
      "156/156 [==============================] - 25s - loss: 1.2011 - acc: 0.4744 - val_loss: 1.2225 - val_acc: 0.5750\n",
      "Epoch 13/30\n",
      "156/156 [==============================] - 22s - loss: 1.1204 - acc: 0.5513 - val_loss: 1.2032 - val_acc: 0.5750\n",
      "Epoch 14/30\n",
      "156/156 [==============================] - 20s - loss: 0.9599 - acc: 0.6026 - val_loss: 1.2224 - val_acc: 0.5750\n",
      "Epoch 15/30\n",
      "156/156 [==============================] - 20s - loss: 0.9360 - acc: 0.6154 - val_loss: 1.1886 - val_acc: 0.5000\n",
      "Epoch 16/30\n",
      "156/156 [==============================] - 21s - loss: 0.8882 - acc: 0.6090 - val_loss: 0.9453 - val_acc: 0.6000\n",
      "Epoch 17/30\n",
      "156/156 [==============================] - 20s - loss: 0.7905 - acc: 0.6474 - val_loss: 0.9256 - val_acc: 0.6250\n",
      "Epoch 18/30\n",
      "156/156 [==============================] - 20s - loss: 0.7310 - acc: 0.6987 - val_loss: 1.4227 - val_acc: 0.4750\n",
      "Epoch 19/30\n",
      "156/156 [==============================] - 20s - loss: 1.0012 - acc: 0.6154 - val_loss: 0.9871 - val_acc: 0.6250\n",
      "Epoch 20/30\n",
      "156/156 [==============================] - 23s - loss: 0.7176 - acc: 0.7051 - val_loss: 0.8605 - val_acc: 0.7000\n",
      "Epoch 21/30\n",
      "156/156 [==============================] - 27s - loss: 0.5651 - acc: 0.8141 - val_loss: 0.7832 - val_acc: 0.7250\n",
      "Epoch 22/30\n",
      "156/156 [==============================] - 23s - loss: 0.4821 - acc: 0.8141 - val_loss: 0.9008 - val_acc: 0.6500\n",
      "Epoch 23/30\n",
      "156/156 [==============================] - 21s - loss: 0.4480 - acc: 0.8333 - val_loss: 0.5949 - val_acc: 0.8250\n",
      "Epoch 24/30\n",
      "156/156 [==============================] - 21s - loss: 0.3997 - acc: 0.8654 - val_loss: 0.5818 - val_acc: 0.7750\n",
      "Epoch 25/30\n",
      "156/156 [==============================] - 22s - loss: 0.3249 - acc: 0.9103 - val_loss: 0.5678 - val_acc: 0.8250\n",
      "Epoch 26/30\n",
      "156/156 [==============================] - 20s - loss: 0.3048 - acc: 0.9231 - val_loss: 0.4692 - val_acc: 0.8500\n",
      "Epoch 27/30\n",
      "156/156 [==============================] - 22s - loss: 0.3024 - acc: 0.9038 - val_loss: 0.5114 - val_acc: 0.8500\n",
      "Epoch 28/30\n",
      "156/156 [==============================] - 23s - loss: 0.2794 - acc: 0.9103 - val_loss: 0.4374 - val_acc: 0.8000\n",
      "Epoch 29/30\n",
      "156/156 [==============================] - 21s - loss: 0.2421 - acc: 0.9167 - val_loss: 0.3933 - val_acc: 0.8500\n",
      "Epoch 30/30\n",
      "156/156 [==============================] - 20s - loss: 0.2468 - acc: 0.9231 - val_loss: 0.4825 - val_acc: 0.7750\n",
      "Test loss: 0.549842768908\n",
      "Test accuracy: 0.819999992847\n"
     ]
    }
   ],
   "source": [
    "#batch_size to train\n",
    "batch_size = 32\n",
    "# number of output classes\n",
    "nb_classes = 5\n",
    "# number of epochs to train\n",
    "nb_epoch = 30\n",
    "\n",
    "\n",
    "# number of convolutional filters to use\n",
    "nb_filters = 32\n",
    "# size of pooling area for max pooling\n",
    "nb_pool = 2\n",
    "# convolution kernel size\n",
    "nb_conv = 3\n",
    "\n",
    "#%%\n",
    "(X, y) = (train_data[0],train_data[1])\n",
    "\n",
    "\n",
    "# STEP 1: split X and y into training and testing sets\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=4)\n",
    "\n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0],img_rows, img_cols,1)\n",
    "X_test = X_test.reshape(X_test.shape[0],img_rows, img_cols,1)\n",
    "\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "\n",
    "print('X_train shape:', X_train.shape)\n",
    "print(X_train.shape[0], 'train samples')\n",
    "print(X_test.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "Y_train = np_utils.to_categorical(y_train, nb_classes)\n",
    "Y_test = np_utils.to_categorical(y_test, nb_classes)\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Convolution2D(nb_filters, nb_conv, nb_conv,\n",
    "                        border_mode='valid',\n",
    "                        input_shape=(img_rows, img_cols,1)))\n",
    "convout1 = Activation('relu')\n",
    "model.add(convout1)\n",
    "model.add(Convolution2D(nb_filters, nb_conv, nb_conv))\n",
    "convout2 = Activation('relu')\n",
    "model.add(convout2)\n",
    "model.add(MaxPooling2D(pool_size=(nb_pool, nb_pool)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(nb_classes))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adadelta',metrics=['accuracy'])\n",
    "         \n",
    "model.fit(X_train, Y_train, batch_size=batch_size, nb_epoch=nb_epoch,verbose=1, validation_split=0.2)\n",
    "score = model.evaluate(X_test, Y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "model.save('keras_cnn_model_our_dataset.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
